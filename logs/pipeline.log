
Pipeline started


Starting preprocessing step...
Loading dataset...
Cleaning text...

===== DATASET STATS =====
Total rows: 372

Label counts:
label
sports      213
politics    159
Name: count, dtype: int64

Avg words per doc: 448
=========================

Saved cleaned dataset → data/dataset_clean.csv

Starting feature building step...
Loading cleaned dataset...
Splitting train/test...

Building Bag of Words features...
BoW vocab size: 16635
BoW train shape: (297, 16635)
BoW features saved
Loading cleaned dataset...
Splitting train/test...

Building TFIDF (1–2 gram) features...
TFIDF vocab size: 50000
TFIDF train shape: (297, 50000)
TFIDF features saved

Starting model training step...
Loading features...

Training Naive Bayes (BoW)...

===== NaiveBayes + BoW =====
Accuracy: 0.9733333333333334

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.94      0.97        32
      sports       0.96      1.00      0.98        43

    accuracy                           0.97        75
   macro avg       0.98      0.97      0.97        75
weighted avg       0.97      0.97      0.97        75

Confusion Matrix:
[[30  2]
 [ 0 43]]

Training Naive Bayes (TFIDF)...

===== NaiveBayes + TFIDF =====
Accuracy: 0.96

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.91      0.95        32
      sports       0.93      1.00      0.97        43

    accuracy                           0.96        75
   macro avg       0.97      0.95      0.96        75
weighted avg       0.96      0.96      0.96        75

Confusion Matrix:
[[29  3]
 [ 0 43]]

Naive Bayes models saved
Loading features...

Training Logistic Regression (BoW)...

===== LogReg + BoW =====
Accuracy: 0.9866666666666667

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.97      0.98        32
      sports       0.98      1.00      0.99        43

    accuracy                           0.99        75
   macro avg       0.99      0.98      0.99        75
weighted avg       0.99      0.99      0.99        75

Confusion Matrix:
[[31  1]
 [ 0 43]]

Training Logistic Regression (TFIDF)...

===== LogReg + TFIDF =====
Accuracy: 0.9733333333333334

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.94      0.97        32
      sports       0.96      1.00      0.98        43

    accuracy                           0.97        75
   macro avg       0.98      0.97      0.97        75
weighted avg       0.97      0.97      0.97        75

Confusion Matrix:
[[30  2]
 [ 0 43]]

Logistic Regression models saved
Loading features...

Training SVM (BoW)...

===== SVM + BoW =====
Accuracy: 0.9866666666666667

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.97      0.98        32
      sports       0.98      1.00      0.99        43

    accuracy                           0.99        75
   macro avg       0.99      0.98      0.99        75
weighted avg       0.99      0.99      0.99        75

Confusion Matrix:
[[31  1]
 [ 0 43]]

Training SVM (TFIDF)...

===== SVM + TFIDF =====
Accuracy: 0.9733333333333334

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.94      0.97        32
      sports       0.96      1.00      0.98        43

    accuracy                           0.97        75
   macro avg       0.98      0.97      0.97        75
weighted avg       0.97      0.97      0.97        75

Confusion Matrix:
[[30  2]
 [ 0 43]]

SVM models saved

Pipeline completed successfully
