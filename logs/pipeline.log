
Pipeline started


Starting preprocessing step...
Loading dataset...
Cleaning text...

===== DATASET STATS =====
Total rows: 159

Label counts:
label
sports      110
politics     49
Name: count, dtype: int64

Avg words per doc: 874
=========================

Saved cleaned dataset → data/dataset_clean.csv

Starting feature building step...
Loading cleaned dataset...
Splitting train/test...

Building Bag of Words features...
BoW vocab size: 13236
BoW train shape: (127, 13236)
BoW features saved
Loading cleaned dataset...
Splitting train/test...

Building TFIDF (1–2 gram) features...
TFIDF vocab size: 50000
TFIDF train shape: (127, 50000)
TFIDF features saved

Starting model training step...
Loading features...

Training Naive Bayes (BoW)...

===== NaiveBayes + BoW =====
Accuracy: 1.0

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      1.00      1.00        10
      sports       1.00      1.00      1.00        22

    accuracy                           1.00        32
   macro avg       1.00      1.00      1.00        32
weighted avg       1.00      1.00      1.00        32

Confusion Matrix:
[[10  0]
 [ 0 22]]

Training Naive Bayes (TFIDF)...

===== NaiveBayes + TFIDF =====
Accuracy: 0.78125

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.30      0.46        10
      sports       0.76      1.00      0.86        22

    accuracy                           0.78        32
   macro avg       0.88      0.65      0.66        32
weighted avg       0.83      0.78      0.74        32

Confusion Matrix:
[[ 3  7]
 [ 0 22]]

Naive Bayes models saved
Loading features...

Training Logistic Regression (BoW)...

===== LogReg + BoW =====
Accuracy: 0.96875

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.90      0.95        10
      sports       0.96      1.00      0.98        22

    accuracy                           0.97        32
   macro avg       0.98      0.95      0.96        32
weighted avg       0.97      0.97      0.97        32

Confusion Matrix:
[[ 9  1]
 [ 0 22]]

Training Logistic Regression (TFIDF)...

===== LogReg + TFIDF =====
Accuracy: 0.78125

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.30      0.46        10
      sports       0.76      1.00      0.86        22

    accuracy                           0.78        32
   macro avg       0.88      0.65      0.66        32
weighted avg       0.83      0.78      0.74        32

Confusion Matrix:
[[ 3  7]
 [ 0 22]]

Logistic Regression models saved
Loading features...

Training SVM (BoW)...

===== SVM + BoW =====
Accuracy: 0.96875

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.90      0.95        10
      sports       0.96      1.00      0.98        22

    accuracy                           0.97        32
   macro avg       0.98      0.95      0.96        32
weighted avg       0.97      0.97      0.97        32

Confusion Matrix:
[[ 9  1]
 [ 0 22]]

Training SVM (TFIDF)...

===== SVM + TFIDF =====
Accuracy: 0.96875

Classification Report:
              precision    recall  f1-score   support

    politics       1.00      0.90      0.95        10
      sports       0.96      1.00      0.98        22

    accuracy                           0.97        32
   macro avg       0.98      0.95      0.96        32
weighted avg       0.97      0.97      0.97        32

Confusion Matrix:
[[ 9  1]
 [ 0 22]]

SVM models saved

Pipeline completed successfully
